{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of Langchain Integration with an Ollama model (qwen2.5:3b quantified) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inférence plus rapide et modèle plus léger avec 3 millions de paramètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current President of France is Emmanuel Macron. He has been in office since May 14, 2017.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "ollama = Ollama(base_url=\"http://localhost:11434\", model=\"qwen2.5:3b\")\n",
    "\n",
    "print(ollama.invoke(\"who is the president of france?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case : RAG from wikipedia page to retrieve contextual info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'Expliques moi en détail le VLM en moins de 500 mots. Appuis toi uniquement sur les informations contenues dans le contexte.', 'result': \"Les VLM (Visual Learning Maps, ou Méthodes de Cartographie Visuelle) sont des outils innovants qui facilitent l'apprentissage en utilisant des cartes visuelles. Ils permettent aux utilisateurs d'élaborer leur propre système de référencement et de connexion entre différents concepts, idées et informations. Cela facilite la compréhension globale et soutient le processus d’apprentissage. \\n\\nL'innovation des VLM tient à leur capacité à offrir un espace en ligne où les utilisateurs peuvent interagir avec ces cartes visuelles. Ils peuvent poser des questions, partager des exemples concrets de leurs applications et recevoir des conseils d'experts qui améliorent leur compréhension et leur utilisation efficace de ces outils innovants.\\n\\nLa diffusion de ces outils novateurs se base sur l'idée que le partage et la collaboration sont essentiels pour maximiser leur potentiel. Les communautés en ligne offrent des plateformes qui facilitent cet échange et favorisent ainsi une compréhension approfondie et un usage optimal de ces outils.\\n\\nEn ce qui concerne l'avenir, les VLM peuvent s'intégrer dans divers cadres utilisateur, se développant constamment pour pallier potentialités inattendues et pour élargir leurs possibilités d'utilisation. Les efforts déployés pour résoudre ces défis contribuent à leur croissance et à leur adoption parmi une large variété de publics.\"}\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# Load the wikipedia page\n",
    "loader = WebBaseLoader(\"https://www.lebigdata.fr/comprendre-les-modeles-de-vision-et-de-langage-un-regard-sur-le-vlm\")\n",
    "docs = loader.load()\n",
    "\n",
    "# Split the page into chunks    \n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# Embed the chunks\n",
    "embedding = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    model_kwargs={\"device\": \"cpu\"}\n",
    ")\n",
    "# Create a vector store\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=all_splits,\n",
    "    embedding=embedding\n",
    ")\n",
    "s\n",
    "# Create a retrieval chain\n",
    "qacahin = RetrievalQA.from_chain_type(\n",
    "    llm=ollama, retriever=vectorstore.as_retriever()\n",
    ")\n",
    "\n",
    "# Query the chain\n",
    "query = \"Expliques moi en détail le VLM en moins de 500 mots.\"\n",
    "\n",
    "print(qacahin({'query': query}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
