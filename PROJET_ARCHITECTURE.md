# Architecture SimplifiÃ©e pour POC RAG Multimodal

```text
ğŸ“ multimodal-poc/
â”œâ”€â”€ ğŸ“ core/                  # CÅ“ur fonctionnel
â”‚   â”œâ”€â”€ ğŸ“„ rag_pipeline.py    # Pipeline principal
â”‚   â”œâ”€â”€ ğŸ“„ embeddings.py      # Gestion des embeddings
â”‚   â””â”€â”€ ğŸ“„ llm_integration.py # IntÃ©gration LLaVA
â”‚
â”œâ”€â”€ ğŸ“ data/                  # DonnÃ©es et modÃ¨les
â”‚   â”œâ”€â”€ ğŸ“ raw/               # DonnÃ©es brutes
â”‚   â”œâ”€â”€ ğŸ“ processed/         # DonnÃ©es vectorisÃ©es
â”‚   â””â”€â”€ ğŸ“ models/            # ModÃ¨les (CLIP, LLaVA)
â”‚
â”œâ”€â”€ ğŸ“ api/                   # API minimale
â”‚   â””â”€â”€ ğŸ“„ app.py             # FastAPI
â”‚
â”œâ”€â”€ ğŸ“ frontend/              # Interface basique
â”‚   â””â”€â”€ ğŸ“„ index.html         # Page unique
â”‚
â”œâ”€â”€ ğŸ“ scripts/               # Utilitaires
â”‚   â”œâ”€â”€ ğŸ“„ setup.sh           # Installation
â”‚   â””â”€â”€ ğŸ“„ ingest.py          # Chargement donnÃ©es
â”‚
â””â”€â”€ ğŸ“„ config.yaml            # Configuration
```

## Composants Essentiels

### 1. Core (ğŸ“ core)
```python
# rag_pipeline.py
class MultimodalRAG:
    def __init__(self):
        self.embedder = ClipEmbedder()
        self.vector_db = FAISS()
        self.llm = LlavaClient()
    
    def query(self, text: str, image: Image) -> str:
        # 1. GÃ©nÃ©rer embedding multimodal
        embedding = self.embedder(text, image)
        
        # 2. Recherche vectorielle
        results = self.vector_db.search(embedding)
        
        # 3. GÃ©nÃ©ration rÃ©ponse
        return self.llm.generate(results)
```

### 2. DonnÃ©es (ğŸ“ data)
```text
data/
â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ ğŸ“„ documents.pdf      # Exemple de donnÃ©es
â”‚   â””â”€â”€ ğŸ“ images/            # Images de test
â”‚
â”œâ”€â”€ processed/
â”‚   â””â”€â”€ ğŸ“„ faiss_index        # Index vectoriel
â”‚
â””â”€â”€ models/
    â”œâ”€â”€ clip/                 # ModÃ¨le CLIP
    â””â”€â”€ llava/               | LLaVA 7B
```

### 3. API (ğŸ“ api)
```python
# app.py
app = FastAPI()

@app.post("/search")
async def search(query: dict):
    return rag_pipeline.query(query["text"], query["image"])
```

### 4. Frontend (ğŸ“ frontend)
```html
<!-- index.html -->
<div class="container">
  <input type="text" id="query">
  <input type="file" id="image">
  <button onclick="search()">Rechercher</button>
  <div id="results"></div>
</div>
```

## Workflow SimplifiÃ©

```mermaid
graph TD
    A[Utilisateur] -->|RequÃªte| B(Frontend)
    B --> C[API]
    C --> D[Core RAG]
    D --> E[(FAISS)]
    E --> F[LLaVA]
    F --> G[RÃ©ponse]
    G --> A
```

## Configuration Minimale
```yaml
# config.yaml
rag:
  model: "llava:7b"
  top_k: 5
  weights:
    text: 0.7
    image: 0.3

storage:
  vector_db: "faiss"
  path: "./data/processed/faiss_index"
```

## Bonnes Pratiques ConservÃ©es

1. **SÃ©paration des responsabilitÃ©s** :  
   - Core (logique mÃ©tier)
   - API (interface)
   - Data (gestion des donnÃ©es)

2. **Configuration externalisÃ©e** :  
   ```python
   # Dans rag_pipeline.py
   import yaml
   
   with open("config.yaml") as f:
       config = yaml.safe_load(f)
   ```

3. **Gestion des dÃ©pendances** :  
   ```bash
   # scripts/setup.sh
   pip install fastapi uvicorn faiss-cpu transformers
   ```

4. **Versioning basique** :  
   ```text
   data/
   â”œâ”€â”€ v1/
   â””â”€â”€ v2/  # Version actuelle
   ```

Cette architecture permet de :
- DÃ©velopper rapidement un prototype fonctionnel
- Maintenir une base Ã©volutive
- Tester les composants clÃ©s (CLIP, LLaVA, FAISS)
- Faciliter la dÃ©mo avec une interface simple

Pour lancer le POC :
```bash
# Installer les dÃ©pendances
bash scripts/setup.sh

# Lancer l'API
uvicorn api.app:app --reload

# Ouvrir le frontend
open frontend/index.html
```
</think>

Voici l'architecture simplifiÃ©e pour votre POC RAG Multimodal :

```markdown:POC_ARCHITECTURE.md
# Architecture POC RAG Multimodal

```text
ğŸ“ multimodal-poc/
â”œâ”€â”€ ğŸ“ core/
â”‚   â”œâ”€â”€ ğŸ“„ rag.py            # Pipeline principal
â”‚   â”œâ”€â”€ ğŸ“„ embeddings.py     # CLIP + combinaison
â”‚   â””â”€â”€ ğŸ“„ llm.py            # IntÃ©gration LLaVA
â”‚
â”œâ”€â”€ ğŸ“ data/
â”‚   â”œâ”€â”€ ğŸ“ raw/              # Documents/Images
â”‚   â””â”€â”€ ğŸ“ vectors/          # Index FAISS
â”‚
â”œâ”€â”€ ğŸ“ api/
â”‚   â””â”€â”€ ğŸ“„ server.py         # API FastAPI
â”‚
â”œâ”€â”€ ğŸ“ web/
â”‚   â””â”€â”€ ğŸ“„ index.html        # Interface simple
â”‚
â””â”€â”€ ğŸ“„ config.py             # ParamÃ¨tres globaux
```

## Fichiers ClÃ©s

**core/rag.py** (CÅ“ur fonctionnel) :
```python
class RAGSystem:
    def __init__(self):
        self.embedder = MultimodalEmbedder()
        self.vector_db = FAISS.load('data/vectors')
        self.llm = LLaVA()
    
    def query(self, text: str, image_path: str):
        embedding = self.embedder(text, image_path)
        results = self.vector_db.search(embedding, top_k=3)
        return self.llm.generate(results)
```

**api/server.py** (Endpoints) :
```python
from fastapi import FastAPI

app = FastAPI()
rag = RAGSystem()

@app.post("/query")
async def handle_query(text: str, image: UploadFile):
    return rag.query(text, image.file)
```

**web/index.html** (Interface) :
```html
<!DOCTYPE html>
<html>
<body>
    <input type="text" id="query" placeholder="Votre question...">
    <input type="file" id="image" accept="image/*">
    <button onclick="submit()">Envoyer</button>
    <div id="result"></div>
</body>
</html>
```

## Workflow d'ExÃ©cution

1. **Installation** :
```bash
pip install fastapi uvicorn faiss-cpu transformers pillow
```

2. **Lancement** :
```bash
uvicorn api.server:app --reload
```

3. **Utilisation** :
```javascript
// Dans index.html
async function submit() {
  const formData = new FormData();
  formData.append('text', document.getElementById('query').value);
  formData.append('image', document.getElementById('image').files[0]);

  const response = await fetch('/query', {
    method: 'POST',
    body: formData
  });
  
  document.getElementById('result').innerText = await response.text();
}
```

Cette architecture minimaliste permet de :
1. Tester rapidement le flux RAG complet
2. Valider les performances de base
3. DÃ©montrer la fonctionnalitÃ© multimodale
4. Servir de base pour l'Ã©volution future

Les composants peuvent Ãªtre Ã©tendus progressivement selon les besoins sans surcharge initiale.