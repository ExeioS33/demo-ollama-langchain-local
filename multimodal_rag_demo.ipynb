{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Démonstration du système RAG Multimodal avec CLIP\n",
                "\n",
                "Ce notebook montre comment utiliser le système de Retrieval Augmented Generation (RAG) multimodal qui permet de combiner des requêtes sur des textes et des images grâce aux embeddings CLIP.\n",
                "\n",
                "Le système permet :\n",
                "- De représenter les textes et les images dans un même espace vectoriel\n",
                "- D'effectuer des requêtes textuelles qui peuvent retourner des images pertinentes\n",
                "- D'effectuer des requêtes avec des images qui peuvent retourner du texte pertinent\n",
                "- D'analyser des documents PDF en extrayant à la fois le texte et les images"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Installation des dépendances\n",
                "\n",
                "Assurez-vous d'avoir installé toutes les dépendances nécessaires :"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install langchain langchain-core langchain-community langchain-ollama\n",
                "!pip install torch transformers clip pymupdf pillow chromadb\n",
                "!pip install matplotlib tqdm numpy requests"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Importation des modules nécessaires\n",
                "\n",
                "Importons les classes du système RAG multimodal ainsi que d'autres bibliothèques utiles :"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import time\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from PIL import Image\n",
                "import requests\n",
                "from io import BytesIO\n",
                "\n",
                "# Importer notre système RAG multimodal\n",
                "from multimodal_rag import MultimodalEmbedder, MultimodalVectorStore, MultimodalRAG"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Vérification d'Ollama\n",
                "\n",
                "Assurons-nous qu'Ollama est en cours d'exécution et que les modèles nécessaires sont disponibles :"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Vérifier si Ollama est en cours d'exécution\n",
                "try:\n",
                "    response = requests.get(\"http://localhost:11434/api/tags\")\n",
                "    if response.status_code == 200:\n",
                "        print(\"✅ Ollama est en cours d'exécution\")\n",
                "        # Afficher les modèles disponibles\n",
                "        models = response.json()[\"models\"]\n",
                "        print(f\"Modèles disponibles: {', '.join([m['name'] for m in models])}\")\n",
                "    else:\n",
                "        print(\"❌ Ollama est en cours d'exécution mais a retourné une erreur\")\n",
                "except Exception as e:\n",
                "    print(f\"❌ Ollama n'est pas en cours d'exécution ou n'est pas accessible: {e}\")\n",
                "    print(\"Lancez Ollama avec la commande: ollama serve\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Initialisation du système RAG multimodal\n",
                "\n",
                "Initialisons notre système RAG multimodal avec le modèle de notre choix :"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Modèle Ollama à utiliser - vous pouvez changer pour un autre modèle disponible\n",
                "LLM_MODEL = \"qwen2.5:3b\"  # ou \"llava:7b\", \"llama2:7b\", etc.\n",
                "\n",
                "# Dossier où seront stockés les embeddings\n",
                "DB_PATH = \"demo_chroma_db\"\n",
                "\n",
                "# Initialiser le système RAG\n",
                "print(f\"Initialisation du système RAG multimodal avec le modèle {LLM_MODEL}...\")\n",
                "rag_system = MultimodalRAG(\n",
                "    llm_name=LLM_MODEL,\n",
                "    collection_name=\"demo_collection\",\n",
                "    persist_directory=DB_PATH\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Exploration des embeddings CLIP\n",
                "\n",
                "CLIP (Contrastive Language-Image Pre-training) est un modèle qui aligne les représentations de texte et d'image dans un même espace vectoriel. Explorons comment cela fonctionne :"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialiser l'embedder CLIP\n",
                "embedder = MultimodalEmbedder()\n",
                "\n",
                "# Exemples de textes\n",
                "texts = [\n",
                "    \"Un chien qui court dans un parc\",\n",
                "    \"Un chat qui dort sur un canapé\",\n",
                "    \"Une voiture rouge garée devant une maison\",\n",
                "    \"Un coucher de soleil sur la plage\",\n",
                "    \"Un ordinateur portable sur un bureau\"\n",
                "]\n",
                "\n",
                "# Générer des embeddings pour ces textes\n",
                "text_embeddings = embedder.embed_text(texts)\n",
                "print(f\"Forme des embeddings de texte: {text_embeddings.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Télécharger quelques images d'exemple\n",
                "image_urls = [\n",
                "    \"https://images.unsplash.com/photo-1543466835-00a7907e9de1?w=500\",  # Chien\n",
                "    \"https://images.unsplash.com/photo-1514888286974-6c03e2ca1dba?w=500\",  # Chat\n",
                "    \"https://images.unsplash.com/photo-1511919884226-fd3cad34687c?w=500\",  # Voiture\n",
                "    \"https://images.unsplash.com/photo-1493514789931-586cb221d7a7?w=500\",  # Coucher de soleil\n",
                "    \"https://images.unsplash.com/photo-1498050108023-c5249f4df085?w=500\"   # Ordinateur\n",
                "]\n",
                "\n",
                "# Télécharger et afficher les images\n",
                "images = []\n",
                "plt.figure(figsize=(15, 10))\n",
                "for i, url in enumerate(image_urls):\n",
                "    response = requests.get(url)\n",
                "    img = Image.open(BytesIO(response.content))\n",
                "    images.append(img)\n",
                "    \n",
                "    plt.subplot(1, 5, i+1)\n",
                "    plt.imshow(img)\n",
                "    plt.title(f\"Image {i+1}\")\n",
                "    plt.axis('off')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Générer des embeddings pour ces images\n",
                "image_embeddings = embedder.embed_image(images)\n",
                "print(f\"Forme des embeddings d'image: {image_embeddings.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Visualisation de la similarité texte-image\n",
                "\n",
                "Un des avantages de CLIP est qu'il place les textes et les images dans le même espace vectoriel, permettant de calculer des similarités entre eux :"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculer la similarité cosinus entre les textes et les images\n",
                "similarity_matrix = np.dot(text_embeddings, image_embeddings.T)\n",
                "\n",
                "# Afficher la matrice de similarité sous forme de heatmap\n",
                "plt.figure(figsize=(10, 8))\n",
                "plt.imshow(similarity_matrix, cmap='viridis')\n",
                "plt.colorbar(label='Similarité cosinus')\n",
                "plt.xticks(range(len(image_urls)), [f\"Image {i+1}\" for i in range(len(image_urls))], rotation=45)\n",
                "plt.yticks(range(len(texts)), [t[:30] + '...' if len(t) > 30 else t for t in texts])\n",
                "plt.title('Similarité entre textes et images')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Afficher les meilleures correspondances\n",
                "for i, text in enumerate(texts):\n",
                "    best_image_idx = np.argmax(similarity_matrix[i])\n",
                "    print(f\"Meilleure image pour '{text}': Image {best_image_idx+1} (similarité: {similarity_matrix[i, best_image_idx]:.4f})\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Création d'une base de connaissances multimodale\n",
                "\n",
                "Créons un dossier pour stocker nos données et ajoutons des documents à notre base de connaissances :"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Créer un dossier pour stocker les fichiers téléchargés\n",
                "os.makedirs('data_demo', exist_ok=True)\n",
                "\n",
                "# Télécharger et sauvegarder les images\n",
                "image_paths = []\n",
                "for i, url in enumerate(image_urls):\n",
                "    response = requests.get(url)\n",
                "    image_path = f\"data_demo/image_{i+1}.jpg\"\n",
                "    with open(image_path, 'wb') as f:\n",
                "        f.write(response.content)\n",
                "    image_paths.append(image_path)\n",
                "    print(f\"Image sauvegardée: {image_path}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Créer quelques fichiers texte d'exemple\n",
                "text_contents = [\n",
                "    \"Les chiens sont des animaux domestiques populaires. Ils sont connus pour leur loyauté et leur amitié. Les chiens peuvent être dressés pour effectuer diverses tâches, comme la garde, l'assistance aux personnes handicapées ou la recherche et le sauvetage.\",\n",
                "    \"Les chats sont des animaux de compagnie indépendants et souvent affectueux. Ils sont connus pour leur agilité et leur capacité à chasser les souris. Les chats passent une grande partie de leur journée à dormir, environ 12 à 16 heures par jour.\",\n",
                "    \"Les voitures sont des véhicules à moteur conçus pour le transport de personnes. Elles ont généralement quatre roues et peuvent accueillir entre une et huit personnes. Les voitures modernes sont équipées de nombreuses fonctionnalités de sécurité et de confort.\",\n",
                "    \"Les couchers de soleil sont un phénomène naturel qui se produit lorsque le Soleil disparaît sous l'horizon. Ils sont souvent caractérisés par des couleurs spectaculaires dans le ciel, allant du jaune et orange au rouge et violet. Les plus beaux couchers de soleil se produisent souvent près de l'eau ou dans des zones avec peu de pollution lumineuse.\",\n",
                "    \"Les ordinateurs portables sont des ordinateurs personnels compacts et facilement transportables. Ils combinent dans un seul appareil un écran, un clavier, un dispositif de pointage et une batterie. Les ordinateurs portables modernes offrent des performances comparables à celles des ordinateurs de bureau.\"\n",
                "]\n",
                "\n",
                "text_paths = []\n",
                "for i, content in enumerate(text_contents):\n",
                "    text_path = f\"data_demo/document_{i+1}.txt\"\n",
                "    with open(text_path, 'w', encoding='utf-8') as f:\n",
                "        f.write(content)\n",
                "    text_paths.append(text_path)\n",
                "    print(f\"Document texte créé: {text_path}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Maintenant, ajoutons ces documents à notre système RAG :"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Ajouter les images avec des descriptions\n",
                "for i, path in enumerate(image_paths):\n",
                "    description = texts[i]  # Utiliser les mêmes textes que précédemment comme descriptions\n",
                "    print(f\"Ajout de l'image {i+1} avec description: '{description[:30]}...'\")\n",
                "    rag_system.add_document(path, document_type=\"image\", description=description)\n",
                "    time.sleep(0.5)  # Pause pour éviter de surcharger le système\n",
                "\n",
                "# Ajouter les textes\n",
                "for i, path in enumerate(text_paths):\n",
                "    print(f\"Ajout du document texte {i+1}\")\n",
                "    rag_system.add_document(path, document_type=\"text\")\n",
                "    time.sleep(0.5)  # Pause pour éviter de surcharger le système\n",
                "\n",
                "print(\"\\nTous les documents ont été ajoutés au système RAG!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Interrogation du système RAG multimodal\n",
                "\n",
                "Maintenant que notre base de connaissances est prête, essayons différentes requêtes pour voir comment le système répond :"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 7.1. Requête textuelle simple"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "query = \"Que font les chats pendant la journée?\"\n",
                "print(f\"Requête: '{query}'\\n\")\n",
                "\n",
                "result = rag_system.query(query)\n",
                "\n",
                "print(\"Réponse:\")\n",
                "print(\"=\" * 50)\n",
                "print(result[\"answer\"])\n",
                "print(\"=\" * 50)\n",
                "\n",
                "print(\"\\nSources utilisées:\")\n",
                "for i, source in enumerate(result[\"sources\"]):\n",
                "    print(f\"Source {i+1} ({source['type']}): {source['metadata'].get('source', 'inconnue')}\")\n",
                "    print(f\"Similarité: {source['similarity']:.4f}\")\n",
                "    print(\"-\" * 40)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 7.2. Requête conceptuelle (peut retourner des images ou du texte)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "query = \"Parle-moi des animaux de compagnie\"\n",
                "print(f\"Requête: '{query}'\\n\")\n",
                "\n",
                "result = rag_system.query(query)\n",
                "\n",
                "print(\"Réponse:\")\n",
                "print(\"=\" * 50)\n",
                "print(result[\"answer\"])\n",
                "print(\"=\" * 50)\n",
                "\n",
                "print(\"\\nSources utilisées:\")\n",
                "for i, source in enumerate(result[\"sources\"]):\n",
                "    print(f\"Source {i+1} ({source['type']}): {source['metadata'].get('source', 'inconnue')}\")\n",
                "    print(f\"Similarité: {source['similarity']:.4f}\")\n",
                "    # Si c'est une image, l'afficher\n",
                "    if source[\"type\"] == \"image\" and \"path\" in source:\n",
                "        img = Image.open(source[\"path\"])\n",
                "        plt.figure(figsize=(5, 5))\n",
                "        plt.imshow(img)\n",
                "        plt.axis('off')\n",
                "        plt.title(f\"Image source {i+1}\")\n",
                "        plt.show()\n",
                "    print(\"-\" * 40)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 7.3. Requête avec une image\n",
                "\n",
                "Maintenant, essayons d'interroger le système avec une image comme entrée :"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Sélectionner une image pour la requête (par exemple, l'image du chat)\n",
                "query_image_path = image_paths[1]\n",
                "\n",
                "# Afficher l'image de requête\n",
                "query_image = Image.open(query_image_path)\n",
                "plt.figure(figsize=(5, 5))\n",
                "plt.imshow(query_image)\n",
                "plt.title(\"Image de requête\")\n",
                "plt.axis('off')\n",
                "plt.show()\n",
                "\n",
                "# Faire la requête avec l'image\n",
                "print(\"Requête: Description de cette image\\n\")\n",
                "result = rag_system.query(query_image_path)\n",
                "\n",
                "print(\"Réponse:\")\n",
                "print(\"=\" * 50)\n",
                "print(result[\"answer\"])\n",
                "print(\"=\" * 50)\n",
                "\n",
                "print(\"\\nSources utilisées:\")\n",
                "for i, source in enumerate(result[\"sources\"]):\n",
                "    print(f\"Source {i+1} ({source['type']}): {source['metadata'].get('source', 'inconnue')}\")\n",
                "    print(f\"Similarité: {source['similarity']:.4f}\")\n",
                "    print(\"-\" * 40)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 7.4. Combinaison texte + image avec une nouvelle image\n",
                "\n",
                "Essayons avec une nouvelle image qui n'est pas dans notre base de connaissances :"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Télécharger une nouvelle image qui n'est pas dans notre base\n",
                "new_image_url = \"https://images.unsplash.com/photo-1583795128727-6ec3642408f8?w=500\"  # Un autre chien\n",
                "response = requests.get(new_image_url)\n",
                "new_image_path = \"data_demo/new_dog.jpg\"\n",
                "with open(new_image_path, 'wb') as f:\n",
                "    f.write(response.content)\n",
                "\n",
                "# Afficher l'image\n",
                "new_image = Image.open(new_image_path)\n",
                "plt.figure(figsize=(5, 5))\n",
                "plt.imshow(new_image)\n",
                "plt.title(\"Nouvelle image (pas dans la base)\")\n",
                "plt.axis('off')\n",
                "plt.show()\n",
                "\n",
                "# Requête spécifique sur cette image\n",
                "query = \"Quelle race de chien est sur cette image et quelles sont les caractéristiques de cette race?\"\n",
                "print(f\"Requête avec image: '{query}'\\n\")\n",
                "\n",
                "# Faire la requête en ajoutant temporairement l'image à la base\n",
                "rag_system.add_document(new_image_path, document_type=\"image\", description=\"Nouvelle image d'un chien\")\n",
                "result = rag_system.query(query)\n",
                "\n",
                "print(\"Réponse:\")\n",
                "print(\"=\" * 50)\n",
                "print(result[\"answer\"])\n",
                "print(\"=\" * 50)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Exemple d'utilisation avec un document PDF\n",
                "\n",
                "Pour montrer comment le système gère les PDF, on peut créer un PDF simple et l'analyser :"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Pour créer un PDF d'exemple, nous allons utiliser fpdf (installer si nécessaire)\n",
                "try:\n",
                "    from fpdf import FPDF\n",
                "except ImportError:\n",
                "    !pip install fpdf\n",
                "    from fpdf import FPDF\n",
                "\n",
                "# Créer un PDF simple avec du texte et une image\n",
                "pdf = FPDF()\n",
                "pdf.add_page()\n",
                "pdf.set_font(\"Arial\", size=12)\n",
                "\n",
                "# Ajouter du texte\n",
                "pdf.cell(200, 10, txt=\"Documentation sur les animaux domestiques\", ln=True, align='C')\n",
                "pdf.ln(10)\n",
                "pdf.multi_cell(0, 10, txt=\"Les chiens et les chats sont les animaux de compagnie les plus populaires dans le monde. Ils offrent de la compagnie et peuvent améliorer la santé mentale de leurs propriétaires.\")\n",
                "pdf.ln(5)\n",
                "pdf.multi_cell(0, 10, txt=\"Les chiens requièrent plus d'attention et d'exercice que les chats. Ils doivent être promenés régulièrement et ont besoin d'interactions sociales.\")\n",
                "pdf.ln(5)\n",
                "pdf.multi_cell(0, 10, txt=\"Les chats sont plus indépendants mais nécessitent tout de même des soins attentifs. Ils aiment avoir des endroits calmes pour se reposer et dormir.\")\n",
                "\n",
                "# Ajouter une image\n",
                "pdf.ln(10)\n",
                "pdf.cell(200, 10, txt=\"Images d'exemples :\", ln=True)\n",
                "pdf.image(image_paths[0], x=30, y=100, w=70)  # Chien\n",
                "pdf.image(image_paths[1], x=110, y=100, w=70)  # Chat\n",
                "\n",
                "# Enregistrer le PDF\n",
                "pdf_path = \"data_demo/animaux_domestiques.pdf\"\n",
                "pdf.output(pdf_path)\n",
                "print(f\"PDF créé: {pdf_path}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Ajouter le PDF à notre système RAG\n",
                "print(\"Ajout du PDF au système RAG...\")\n",
                "pdf_ids = rag_system.add_document(pdf_path)\n",
                "print(f\"PDF ajouté avec succès! ({len(pdf_ids)} éléments indexés)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Interroger notre système sur le contenu du PDF\n",
                "query = \"Quelle est la différence entre les chiens et les chats ?\"\n",
                "print(f\"Requête: '{query}'\\n\")\n",
                "\n",
                "result = rag_system.query(query)\n",
                "\n",
                "print(\"Réponse:\")\n",
                "print(\"=\" * 50)\n",
                "print(result[\"answer\"])\n",
                "print(\"=\" * 50)\n",
                "\n",
                "print(\"\\nSources utilisées:\")\n",
                "for i, source in enumerate(result[\"sources\"]):\n",
                "    source_type = source[\"type\"]\n",
                "    source_info = source[\"metadata\"].get(\"source\", \"inconnue\")\n",
                "    page_info = f\" (page {source['metadata']['page']})\" if \"page\" in source[\"metadata\"] else \"\"\n",
                "    similarity = source[\"similarity\"]\n",
                "    \n",
                "    print(f\"Source {i+1} ({source_type}){page_info}: {source_info}\")\n",
                "    print(f\"Similarité: {similarity:.4f}\")\n",
                "    \n",
                "    # Si c'est une image extraite du PDF, l'afficher\n",
                "    if source_type == \"image\" and \"path\" in source and \"pdf_image\" in source[\"metadata\"].get(\"type\", \"\"):\n",
                "        img = Image.open(source[\"path\"])\n",
                "        plt.figure(figsize=(5, 5))\n",
                "        plt.imshow(img)\n",
                "        plt.axis('off')\n",
                "        plt.title(f\"Image extraite du PDF (page {source['metadata']['page']})\")\n",
                "        plt.show()\n",
                "    \n",
                "    print(\"-\" * 40)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Conclusion\n",
                "\n",
                "Ce notebook a démontré comment le système RAG multimodal peut être utilisé pour combiner des informations textuelles et visuelles dans un même système de question-réponse. Les avantages principaux sont :\n",
                "\n",
                "1. **Unification des modalités** : Un seul système peut traiter à la fois du texte et des images.\n",
                "2. **Requêtes cross-modales** : Une requête textuelle peut retourner des images pertinentes et vice versa.\n",
                "3. **Flexibilité** : Le système peut être utilisé pour diverses applications comme la documentation technique, les catalogues de produits, l'analyse de PDFs, etc.\n",
                "4. **Extensibilité** : D'autres types de documents peuvent être facilement intégrés.\n",
                "\n",
                "Pour aller plus loin, il serait possible d'étendre ce système pour prendre en charge d'autres modalités comme l'audio ou la vidéo, ou d'améliorer les performances en utilisant des modèles d'embedding plus récents."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}