# Makefile pour le système RAG Multimodal Amélioré avec FAISS
#
# Ce Makefile fournit des commandes pour faciliter l'utilisation
# du système RAG multimodal optimisé avec FAISS et reranking
# qui permet d'analyser des textes, images et PDFs avec une
# meilleure précision et performance.

# Configuration
PYTHON = python3
MODEL = qwen2.5:3b
DB_PATH = ./enhanced_vector_store
COLLECTION = enhanced_multimodal_collection
CHROMA_PATH = ./chroma_db
CHROMA_COLLECTION = multimodal_collection
GPU = false
SIMILARITY = 0.2
RERANKER = cross-encoder/ms-marco-MiniLM-L-6-v2

# Installation des dépendances
install:
	pip install -r requirements.txt
	@echo "✅ Dépendances installées"

# Vérifier si Ollama est en cours d'exécution
check-ollama:
	@curl -s http://localhost:11434/api/tags > /dev/null && echo "✅ Ollama est en cours d'exécution" || (echo "❌ Ollama n'est pas en cours d'exécution. Lancez Ollama avec 'make start-ollama'"; exit 1)

# Démarrer Ollama (en arrière-plan)
start-ollama:
	@echo "Démarrage d'Ollama..."
	@ollama serve > ollama.log 2>&1 &
	@echo "✅ Ollama démarré en arrière-plan (logs dans ollama.log)"

# Télécharger les modèles Ollama nécessaires
download-models:
	@echo "Téléchargement des modèles..."
	@ollama pull qwen2.5:3b
	@ollama pull llava
	@echo "✅ Modèles téléchargés"

# Réinitialiser la base de données FAISS
reset-db:
	$(PYTHON) enhanced_multimodal_rag_demo.py --reset --db-path $(DB_PATH) --collection $(COLLECTION) --model $(MODEL)
	@echo "✅ Base de données FAISS réinitialisée"

# Migrer depuis une base ChromaDB existante
migrate:
	$(PYTHON) enhanced_multimodal_rag_demo.py --migrate --chroma-path $(CHROMA_PATH) --chroma-collection $(CHROMA_COLLECTION) --db-path $(DB_PATH) --model $(MODEL) $(if $(filter true,$(GPU)),--use-gpu,)
	@echo "✅ Migration depuis ChromaDB vers FAISS terminée"

# Ajouter un document (auto-détection du type)
add-document: check-ollama
	@read -p "Chemin du document (PDF, image, texte): " path; \
	read -p "Description (optionnelle, pour les images): " desc; \
	if [ -z "$$desc" ]; then \
		$(PYTHON) enhanced_multimodal_rag_demo.py --add-document $$path --model $(MODEL) --db-path $(DB_PATH) --collection $(COLLECTION) $(if $(filter true,$(GPU)),--use-gpu,) --similarity-threshold $(SIMILARITY) --reranker $(RERANKER); \
	else \
		$(PYTHON) enhanced_multimodal_rag_demo.py --add-document $$path --description "$$desc" --model $(MODEL) --db-path $(DB_PATH) --collection $(COLLECTION) $(if $(filter true,$(GPU)),--use-gpu,) --similarity-threshold $(SIMILARITY) --reranker $(RERANKER); \
	fi

# Faire une requête textuelle
query: check-ollama
	@read -p "Votre question: " question; \
	$(PYTHON) enhanced_multimodal_rag_demo.py --query "$$question" --model $(MODEL) --db-path $(DB_PATH) --collection $(COLLECTION) $(if $(filter true,$(GPU)),--use-gpu,) --similarity-threshold $(SIMILARITY) --reranker $(RERANKER)

# Faire une requête avec une image
image-query: check-ollama
	@read -p "Chemin de l'image de requête: " path; \
	$(PYTHON) enhanced_multimodal_rag_demo.py --image-query $$path --model $(MODEL) --db-path $(DB_PATH) --collection $(COLLECTION) $(if $(filter true,$(GPU)),--use-gpu,) --similarity-threshold $(SIMILARITY) --reranker $(RERANKER)

# Faire une requête sans reranking (pour comparer)
query-no-rerank: check-ollama
	@read -p "Votre question: " question; \
	$(PYTHON) enhanced_multimodal_rag_demo.py --query "$$question" --model $(MODEL) --db-path $(DB_PATH) --collection $(COLLECTION) $(if $(filter true,$(GPU)),--use-gpu,) --similarity-threshold $(SIMILARITY) --no-reranking

# Changer le modèle LLM
set-model:
	@read -p "Nouveau modèle (ex: llava, qwen2.5:3b): " model; \
	echo "MODEL = $$model" > .model_config; \
	echo "✅ Modèle changé à: $$model"
	@echo "Utilisez 'make' avec les autres commandes pour appliquer ce changement"

# Activer/désactiver le GPU
toggle-gpu:
	@if [ "$(GPU)" = "true" ]; then \
		echo "GPU = false" > .gpu_config; \
		echo "✅ Mode GPU désactivé"; \
	else \
		echo "GPU = true" > .gpu_config; \
		echo "✅ Mode GPU activé"; \
	fi
	@echo "Utilisez 'make' avec les autres commandes pour appliquer ce changement"

# Modifier le seuil de similarité
set-similarity:
	@read -p "Nouveau seuil de similarité (0.0-1.0, recommandé: 0.2-0.4): " sim; \
	echo "SIMILARITY = $$sim" > .similarity_config; \
	echo "✅ Seuil de similarité changé à: $$sim"
	@echo "Utilisez 'make' avec les autres commandes pour appliquer ce changement"

# Changer le modèle de reranking
set-reranker:
	@read -p "Nouveau modèle de reranking: " reranker; \
	echo "RERANKER = $$reranker" > .reranker_config; \
	echo "✅ Modèle de reranking changé à: $$reranker"
	@echo "Utilisez 'make' avec les autres commandes pour appliquer ce changement"

# Obtenir des informations sur la configuration
config-info:
	@echo "Configuration actuelle:"
	@echo "  Modèle LLM: $(MODEL)"
	@echo "  Base de données FAISS: $(DB_PATH)"
	@echo "  Collection: $(COLLECTION)"
	@echo "  Utilisation GPU: $(GPU)"
	@echo "  Seuil de similarité: $(SIMILARITY)"
	@echo "  Modèle de reranking: $(RERANKER)"

# Compare performance (ancienne vs nouvelle implémentation)
compare-performance: check-ollama
	@read -p "Votre question pour la comparaison: " question; \
	echo "\n=== PERFORMANCE AVEC CHROMADB (ORIGINAL) ==="; \
	time $(PYTHON) multimodal_rag_demo.py --query "$$question" --model $(MODEL) --db_path $(CHROMA_PATH) --collection $(CHROMA_COLLECTION); \
	echo "\n=== PERFORMANCE AVEC FAISS (AMÉLIORÉ) ==="; \
	time $(PYTHON) enhanced_multimodal_rag_demo.py --query "$$question" --model $(MODEL) --db-path $(DB_PATH) --collection $(COLLECTION) $(if $(filter true,$(GPU)),--use-gpu,)

# Démo complète
demo: check-ollama
	@echo "\n======= DÉMO DU SYSTÈME RAG MULTIMODAL AMÉLIORÉ =======\n"
	@echo "Configuration: Model=$(MODEL), GPU=$(GPU), Similarité=$(SIMILARITY)"
	@echo "\n1. Ajout d'un document texte de test..."
	@echo "Ceci est un document de test pour démontrer le système RAG multimodal amélioré avec FAISS et reranking." > test_document.txt
	$(PYTHON) enhanced_multimodal_rag_demo.py --add-document test_document.txt --model $(MODEL) --db-path $(DB_PATH) --collection $(COLLECTION) $(if $(filter true,$(GPU)),--use-gpu,) --similarity-threshold $(SIMILARITY)
	
	@echo "\n2. Interrogation du système..."
	$(PYTHON) enhanced_multimodal_rag_demo.py --query "Explique ce qu'est le système RAG?" --model $(MODEL) --db-path $(DB_PATH) --collection $(COLLECTION) $(if $(filter true,$(GPU)),--use-gpu,) --similarity-threshold $(SIMILARITY)
	
	@echo "\n3. Comparaison avec/sans reranking..."
	@echo "\n=== AVEC RERANKING ==="
	$(PYTHON) enhanced_multimodal_rag_demo.py --query "Que démontre ce document?" --model $(MODEL) --db-path $(DB_PATH) --collection $(COLLECTION) $(if $(filter true,$(GPU)),--use-gpu,) --similarity-threshold $(SIMILARITY)
	@echo "\n=== SANS RERANKING ==="
	$(PYTHON) enhanced_multimodal_rag_demo.py --query "Que démontre ce document?" --model $(MODEL) --db-path $(DB_PATH) --collection $(COLLECTION) $(if $(filter true,$(GPU)),--use-gpu,) --similarity-threshold $(SIMILARITY) --no-reranking
	
	@echo "\n✅ Démo terminée - Nettoyage..."
	rm test_document.txt
	@echo "✅ Fichier de test supprimé"

# Aide
help:
	@echo "Commandes disponibles pour le système RAG multimodal amélioré:"
	@echo "  make install             : Installer les dépendances"
	@echo "  make start-ollama        : Démarrer Ollama en arrière-plan"
	@echo "  make download-models     : Télécharger les modèles nécessaires"
	@echo "  make reset-db            : Réinitialiser la base de données FAISS"
	@echo "  make migrate             : Migrer depuis une base ChromaDB existante"
	@echo "  make add-document        : Ajouter un document (PDF, image, texte)"
	@echo "  make query               : Faire une requête textuelle"
	@echo "  make image-query         : Faire une requête avec une image"
	@echo "  make query-no-rerank     : Faire une requête sans reranking"
	@echo "  make set-model           : Changer le modèle LLM"
	@echo "  make toggle-gpu          : Activer/désactiver le mode GPU"
	@echo "  make set-similarity      : Modifier le seuil de similarité"
	@echo "  make set-reranker        : Changer le modèle de reranking"
	@echo "  make config-info         : Afficher la configuration actuelle"
	@echo "  make compare-performance : Comparer les performances (original vs amélioré)"
	@echo "  make demo                : Exécuter une démonstration complète"
	@echo ""
	@echo "Configuration actuelle:"
	@echo "  Modèle LLM: $(MODEL)"
	@echo "  Base de données FAISS: $(DB_PATH)"
	@echo "  Collection: $(COLLECTION)"
	@echo "  Utilisation GPU: $(GPU)"
	@echo "  Seuil de similarité: $(SIMILARITY)"
	@echo "  Modèle de reranking: $(RERANKER)"
	@echo ""
	@echo "Vous pouvez également spécifier ces paramètres directement:"
	@echo "  make query MODEL=llava GPU=true SIMILARITY=0.3"

# Inclure les fichiers de configuration si disponibles
-include .model_config
-include .gpu_config
-include .similarity_config
-include .reranker_config

.PHONY: install check-ollama start-ollama download-models reset-db migrate add-document query image-query query-no-rerank set-model toggle-gpu set-similarity set-reranker config-info compare-performance demo help 